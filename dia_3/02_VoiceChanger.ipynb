{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversor de Voz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice el siguiente código para convertir una forma de onda de voz mono de 16 kHz en otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForSpeechToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "dataset = dataset.sort(\"id\")\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "example_speech = dataset[0][\"audio\"][\"array\"]\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_vc\")\n",
    "model = SpeechT5ForSpeechToSpeech.from_pretrained(\"microsoft/speecht5_vc\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "inputs = processor(audio=example_speech, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "# load xvector containing speaker's voice characteristics from a file\n",
    "speaker_embeddings = torch.zeros((1, 512))  # or load xvectors from a file\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_values\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "import soundfile as sf\n",
    "sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora extraemos las caracteristicas de una voz diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", savedir=\"pretrained_models/spkrec-xvect-voxceleb\")\n",
    "signal, fs =torchaudio.load('tests/samples/ASR/spk1_snt1.wav')\n",
    "embeddings = classifier.encode_batch(signal)\n",
    "# Podemos guardarlas y cargarlas luego con:\n",
    "# speaker_embeddings = np.load(\"xvector_speaker_embedding.npy\")\n",
    "# speaker_embeddings = torch.tensor(speaker_embeddings).unsqueeze(0)\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_values\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "import soundfile as sf\n",
    "sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, analizemos el interior de este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora utilizaremos un conversor voz, basado en TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, instalamos la libreria necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice el siguiente código para convertir un texto a una forma de onda de voz mono de 16 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "import os\n",
    "\n",
    "CACHE_MODEL_DIR = \"./models\"\n",
    "\n",
    "model_path = snapshot_download(\n",
    "    repo_id=\"coqui/XTTS-v2\",\n",
    "    cache_dir=CACHE_MODEL_DIR\n",
    ")\n",
    "\n",
    "config = XttsConfig()\n",
    "config.load_json(os.path.join(model_path, \"config.json\"))\n",
    "model = Xtts.init_from_config(config)\n",
    "model.load_checkpoint(config, checkpoint_dir=model_path, eval=True)\n",
    "model.cuda()\n",
    "\n",
    "mensaje = \"Me llevo un tiempo desarrollar una voz y ahora que la tengo no pienso quedarme callada\"\n",
    "\n",
    "speaker_wav = \"audio_loc.wav\"\n",
    "outputs = model.synthesize(\n",
    "    mensaje,\n",
    "    config,\n",
    "    speaker_wav=speaker_wav,\n",
    "    gpt_cond_len=3,\n",
    "    language=\"es\",\n",
    ")\n",
    "\n",
    "Audio(outputs[\"wav\"], rate=24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, analizemos el interior de este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
